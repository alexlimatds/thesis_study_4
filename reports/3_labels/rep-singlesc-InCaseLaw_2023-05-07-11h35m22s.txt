RESULTS REPORT (SINGLE SENTENCE CLASSIFICATION)
Model: InCaseLaw
Encoder: law-ai/InCaseLawBERT
Dataset: facts
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Freeze layers: False
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h50m28s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    0.452591  0.007184  0.300370 0.017615   0.7194  0.0116   0.7405  0.0161   0.7265   0.0057
  2    0.327652  0.002509  0.306757 0.006159   0.7207  0.0116   0.7455  0.0126   0.7301   0.0058
  3    0.272790  0.002023  0.329816 0.002075   0.7127  0.0084   0.7513  0.0142   0.7279   0.0060
  4    0.232237  0.003310  0.358001 0.002370   0.7020  0.0068   0.7531  0.0084   0.7215   0.0070

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
Other: 2 
=> Iteration 0:
Epoch 1:
[[ 264    4  124]
 [   1   25   11]
 [ 102   21 1645]]
Epoch 2:
[[ 268    3  121]
 [   0   25   12]
 [ 121   23 1624]]
Epoch 3:
[[ 249    3  140]
 [   0   24   13]
 [  98   20 1650]]
Epoch 4:
[[ 260    3  129]
 [   0   25   12]
 [ 113   27 1628]]
=> Iteration 1:
Epoch 1:
[[ 246    2  144]
 [   0   21   16]
 [  83   16 1669]]
Epoch 2:
[[ 225    2  165]
 [   0   24   13]
 [  72   18 1678]]
Epoch 3:
[[ 249    2  141]
 [   0   25   12]
 [  98   22 1648]]
Epoch 4:
[[ 256    2  134]
 [   1   25   11]
 [ 105   23 1640]]
=> Iteration 2:
Epoch 1:
[[ 254    2  136]
 [   1   24   12]
 [  90   19 1659]]
Epoch 2:
[[ 262    2  128]
 [   0   23   14]
 [ 110   18 1640]]
Epoch 3:
[[ 282    2  108]
 [   0   26   11]
 [ 129   25 1614]]
Epoch 4:
[[ 266    3  123]
 [   0   26   11]
 [ 112   23 1633]]
=> Iteration 3:
Epoch 1:
[[ 286    3  103]
 [   1   23   13]
 [ 156   18 1594]]
Epoch 2:
[[ 267    2  123]
 [   0   24   13]
 [ 115   19 1634]]
Epoch 3:
[[ 255    2  135]
 [   0   24   13]
 [ 115   21 1632]]
Epoch 4:
[[ 244    3  145]
 [   0   25   12]
 [ 100   24 1644]]
=> Iteration 4:
Epoch 1:
[[ 239    3  150]
 [   1   24   12]
 [  79   21 1668]]
Epoch 2:
[[ 269    2  121]
 [   0   24   13]
 [ 114   17 1637]]
Epoch 3:
[[ 252    2  138]
 [   0   25   12]
 [  98   19 1651]]
Epoch 4:
[[ 253    3  136]
 [   1   25   11]
 [ 106   24 1638]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.445880   0.300546   0.714501   0.759858    0.732549
Iteration 1    0.443172   0.291852   0.732901   0.713041    0.721004
Iteration 2    0.454119   0.289071   0.729221   0.744985    0.734253
Iteration 3    0.462663   0.334256   0.700163   0.750932    0.723183
Iteration 4    0.457121   0.286127   0.720231   0.733927    0.721393

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.326410   0.304947   0.701148   0.759300    0.725300
Iteration 1    0.324521   0.314638   0.735708   0.723908    0.723921
Iteration 2    0.326463   0.297343   0.719833   0.739197    0.728269
Iteration 3    0.329153   0.304550   0.718483   0.751326    0.732991
Iteration 4    0.331711   0.312306   0.728275   0.753593    0.739771

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.269019   0.328070   0.714453   0.739037    0.723141
Iteration 1    0.273754   0.331001   0.714277   0.747669    0.726262
Iteration 2    0.272788   0.332335   0.702677   0.778329    0.734055
Iteration 3    0.275024   0.330935   0.705560   0.740745    0.720225
Iteration 4    0.273362   0.326738   0.726730   0.750785    0.735615

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.227268   0.359883   0.690630   0.753252    0.714590
Iteration 1    0.230427   0.359925   0.708650   0.752113    0.725640
Iteration 2    0.236813   0.354710   0.709290   0.768306    0.733028
Iteration 3    0.234652   0.359965   0.700966   0.742663    0.715369
Iteration 4    0.232027   0.355522   0.700398   0.749185    0.718903

