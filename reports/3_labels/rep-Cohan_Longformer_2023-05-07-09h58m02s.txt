RESULTS REPORT - Cohan
Model: Longformer
Encoder: allenai/longformer-base-4096
Dataset: facts
Chunk layout: Cohan
Evaluation: test set (5 random seeds)
Max sequence length: 1024
Max sentence length: 85
Max sentences per chunk: 14
Batch size: 4
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 01h29m45s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    0.568525  0.018870  0.316944 0.029340   0.8156  0.1439   0.5627  0.0121   0.5817   0.0347
  2    0.408984  0.008200  0.329100 0.032659   0.7806  0.0685   0.6479  0.0351   0.6788   0.0093
  3    0.329620  0.009053  0.324256 0.010437   0.7787  0.0479   0.6629  0.0309   0.6989   0.0142
  4    0.276224  0.009496  0.337610 0.016269   0.7707  0.0349   0.6882  0.0137   0.7198   0.0143

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
Other: 2 
=> Iteration 0:
Epoch 1:
[[ 273    0  119]
 [   2    2   33]
 [ 107    0 1661]]
Epoch 2:
[[ 272    0  120]
 [   4    9   24]
 [ 103    1 1664]]
Epoch 3:
[[ 260    0  132]
 [   3   14   20]
 [  78    8 1682]]
Epoch 4:
[[ 260    0  132]
 [   2   16   19]
 [  96   16 1656]]
=> Iteration 1:
Epoch 1:
[[ 254    0  138]
 [   1    1   35]
 [  58    0 1710]]
Epoch 2:
[[ 261    0  131]
 [   4   10   23]
 [  68    2 1698]]
Epoch 3:
[[ 261    0  131]
 [   2   11   24]
 [  75    2 1691]]
Epoch 4:
[[ 273    0  119]
 [   4   14   19]
 [  80    4 1684]]
=> Iteration 2:
Epoch 1:
[[ 306    0   86]
 [   8    0   29]
 [ 155    0 1613]]
Epoch 2:
[[ 237    7  148]
 [   1   21   15]
 [  55   41 1672]]
Epoch 3:
[[ 247    0  145]
 [   0   16   21]
 [  64   11 1693]]
Epoch 4:
[[ 275    0  117]
 [   3   15   19]
 [  98    7 1663]]
=> Iteration 3:
Epoch 1:
[[ 269    0  123]
 [   3    1   33]
 [  85    0 1683]]
Epoch 2:
[[ 274    0  118]
 [   1   14   22]
 [ 118   11 1639]]
Epoch 3:
[[ 264    0  128]
 [   4    9   24]
 [  79    3 1686]]
Epoch 4:
[[ 293    0   99]
 [   2   17   18]
 [ 112    8 1648]]
=> Iteration 4:
Epoch 1:
[[ 229    0  163]
 [   0    7   30]
 [  39    1 1728]]
Epoch 2:
[[ 228    0  164]
 [   0   10   27]
 [  50    4 1714]]
Epoch 3:
[[ 283    1  108]
 [   4   18   15]
 [  98   22 1648]]
Epoch 4:
[[ 249    2  141]
 [   0   18   19]
 [  68   11 1689]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.536160   0.303070   0.876940   0.563321    0.578555
Iteration 1    0.578781   0.277863   0.906542   0.547394    0.569976
Iteration 2    0.593278   0.367741   0.528634   0.564314    0.544523
Iteration 3    0.569592   0.317136   0.889558   0.555058    0.568036
Iteration 4    0.564814   0.318912   0.876336   0.583583    0.647297

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.412748   0.359041   0.846011   0.626099    0.673068
Iteration 1    0.397167   0.301197   0.844655   0.632165    0.688762
Iteration 2    0.417674   0.376445   0.674798   0.705954    0.672104
Iteration 3    0.415969   0.314331   0.726168   0.668131    0.691288
Iteration 4    0.401360   0.294485   0.811389   0.607120    0.668684

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.337193   0.324483   0.771983   0.664334    0.705972
Iteration 1    0.320634   0.324661   0.844793   0.639854    0.696958
Iteration 2    0.341963   0.327998   0.765836   0.673371    0.712086
Iteration 3    0.329615   0.305932   0.809369   0.623444    0.672311
Iteration 4    0.318697   0.338208   0.701546   0.713517    0.707106

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.278416   0.359995   0.714231   0.677450    0.694512
Iteration 1    0.265581   0.315757   0.822248   0.675765    0.725408
Iteration 2    0.292461   0.351919   0.779201   0.682516    0.719019
Iteration 3    0.276737   0.326328   0.777871   0.713012    0.738241
Iteration 4    0.267926   0.334052   0.759867   0.692336    0.721911

