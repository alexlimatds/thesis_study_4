RESULTS REPORT - DFCSC-SEP
Model: RoBERTa
Encoder: roberta-base
Dataset: facts
Evaluation: test set (5 random seeds)
Max sequence length: 512
Min context length: 250
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 00h33m04s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    0.478469  0.019033  0.297971 0.012326   0.7484  0.1189   0.6524  0.0474   0.6717   0.0540
  2    0.322880  0.005142  0.270969 0.025754   0.8004  0.0247   0.7068  0.0250   0.7410   0.0142
  3    0.258448  0.002112  0.282033 0.009617   0.7777  0.0101   0.7508  0.0174   0.7624   0.0085
  4    0.221664  0.003060  0.276562 0.011679   0.7856  0.0067   0.7333  0.0174   0.7569   0.0126

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
Other: 2 
=> Iteration 0:
Epoch 1:
[[ 320    0   72]
 [   3    9   25]
 [ 123    2 1643]]
Epoch 2:
[[ 303    0   89]
 [   3   18   16]
 [  83   12 1673]]
Epoch 3:
[[ 269    0  123]
 [   1   20   16]
 [  63   13 1692]]
Epoch 4:
[[ 278    0  114]
 [   2   17   18]
 [  68   11 1689]]
=> Iteration 1:
Epoch 1:
[[ 300    0   92]
 [   1   14   22]
 [  93   13 1662]]
Epoch 2:
[[ 312    0   80]
 [   1   13   23]
 [ 104    5 1659]]
Epoch 3:
[[ 279    0  113]
 [   1   20   16]
 [  79   11 1678]]
Epoch 4:
[[ 293    0   99]
 [   1   20   16]
 [  86   11 1671]]
=> Iteration 2:
Epoch 1:
[[ 245    0  147]
 [   1    9   27]
 [  56    0 1712]]
Epoch 2:
[[ 244    0  148]
 [   1   15   21]
 [  52    6 1710]]
Epoch 3:
[[ 298    0   94]
 [   1   22   14]
 [ 100   10 1658]]
Epoch 4:
[[ 266    0  126]
 [   1   22   14]
 [  67   11 1690]]
=> Iteration 3:
Epoch 1:
[[ 322    0   70]
 [  10    0   27]
 [ 121    0 1647]]
Epoch 2:
[[ 290    0  102]
 [   2   16   19]
 [  64    5 1699]]
Epoch 3:
[[ 327    0   65]
 [   1   21   15]
 [ 131   13 1624]]
Epoch 4:
[[ 280    0  112]
 [   1   18   18]
 [  73   11 1684]]
=> Iteration 4:
Epoch 1:
[[ 324    1   67]
 [   3   14   20]
 [ 131   13 1624]]
Epoch 2:
[[ 308    0   84]
 [   3   17   17]
 [ 102   10 1656]]
Epoch 3:
[[ 279    1  112]
 [   1   22   14]
 [  58   16 1694]]
Epoch 4:
[[ 292    0  100]
 [   1   21   15]
 [  81   11 1676]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.465792   0.308610   0.826641   0.662956    0.691813
Iteration 1    0.501203   0.304176   0.738584   0.694577    0.712927
Iteration 2    0.488009   0.280084   0.906333   0.612190    0.678137
Iteration 3    0.489294   0.286502   0.551733   0.584330    0.566686
Iteration 4    0.448048   0.310481   0.718859   0.707820    0.708908

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.316221   0.250968   0.773288   0.735238    0.752280
Iteration 1    0.331209   0.269747   0.803989   0.695206    0.727998
Iteration 2    0.324800   0.315248   0.815298   0.665016    0.721090
Iteration 3    0.319041   0.240890   0.836676   0.711067    0.758057
Iteration 4    0.323130   0.277990   0.772636   0.727275    0.745347

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.255510   0.273404   0.779318   0.727926    0.751253
Iteration 1    0.259948   0.273154   0.783644   0.733790    0.756662
Iteration 2    0.258736   0.299615   0.791071   0.764194    0.776490
Iteration 3    0.261333   0.281844   0.761039   0.773434    0.765180
Iteration 4    0.256713   0.282148   0.773439   0.754825    0.762530

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.216069   0.269651   0.777835   0.707987    0.738546
Iteration 1    0.225311   0.281184   0.783941   0.744375    0.762551
Iteration 2    0.221811   0.297442   0.795524   0.743016    0.766922
Iteration 3    0.222024   0.265837   0.779995   0.717754    0.745461
Iteration 4    0.223104   0.268694   0.790930   0.753476    0.770978

