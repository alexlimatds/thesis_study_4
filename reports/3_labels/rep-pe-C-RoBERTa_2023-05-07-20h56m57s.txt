RESULTS REPORT (PE C)
Model: RoBERTa
Encoder: roberta-base
Dataset: facts
Evaluation: test set (5 random seeds)
Combination: C
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h51m48s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    0.558331  0.024391  0.366194 0.010705   0.7323  0.0944   0.5234  0.0191   0.5647   0.0310
  2    0.406867  0.015100  0.352014 0.026026   0.7141  0.0623   0.6300  0.0638   0.6499   0.0325
  3    0.338770  0.009475  0.355624 0.019251   0.7071  0.0272   0.6747  0.0447   0.6843   0.0281
  4    0.288793  0.006455  0.360991 0.009614   0.7098  0.0209   0.7001  0.0242   0.7012   0.0180

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
Other: 2 
=> Iteration 0:
Epoch 1:
[[ 156    3  233]
 [   1    8   28]
 [  43    8 1717]]
Epoch 2:
[[ 140    1  251]
 [   3    9   25]
 [  27    1 1740]]
Epoch 3:
[[ 225    3  164]
 [   2   19   16]
 [  79   12 1677]]
Epoch 4:
[[ 248    3  141]
 [   2   23   12]
 [  98   16 1654]]
=> Iteration 1:
Epoch 1:
[[ 191    0  201]
 [   4    1   32]
 [  67    0 1701]]
Epoch 2:
[[ 210    3  179]
 [   1   17   19]
 [  78   13 1677]]
Epoch 3:
[[ 269    5  118]
 [   0   25   12]
 [ 151   22 1595]]
Epoch 4:
[[ 219    3  170]
 [   0   21   16]
 [  81   12 1675]]
=> Iteration 2:
Epoch 1:
[[ 171    1  220]
 [   6    6   25]
 [  32    2 1734]]
Epoch 2:
[[ 252    4  136]
 [   4   17   16]
 [  98   23 1647]]
Epoch 3:
[[ 230    3  159]
 [   3   16   18]
 [  75   12 1681]]
Epoch 4:
[[ 235    3  154]
 [   3   23   11]
 [  83   22 1663]]
=> Iteration 3:
Epoch 1:
[[ 212    2  178]
 [   9    3   25]
 [ 109    8 1651]]
Epoch 2:
[[ 218    3  171]
 [   3   10   24]
 [  91    9 1668]]
Epoch 3:
[[ 175    3  214]
 [   3   17   17]
 [  66   22 1680]]
Epoch 4:
[[ 216    3  173]
 [   2   18   17]
 [  81   16 1671]]
=> Iteration 4:
Epoch 1:
[[ 149    4  239]
 [   1   11   25]
 [  33    7 1728]]
Epoch 2:
[[ 242    5  145]
 [   3   21   13]
 [  88   31 1649]]
Epoch 3:
[[ 206    3  183]
 [   1   19   17]
 [  65   13 1690]]
Epoch 4:
[[ 235    3  154]
 [   2   21   14]
 [ 106   24 1638]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.592418   0.360442   0.689700   0.528443    0.576484
Iteration 1    0.538380   0.363776   0.869511   0.492125    0.518564
Iteration 2    0.542591   0.353067   0.787016   0.526385    0.585154
Iteration 3    0.534992   0.385058   0.587900   0.518574    0.539636
Iteration 4    0.583276   0.368629   0.727226   0.551592    0.603430

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.431193   0.393435   0.834935   0.528183    0.597627
Iteration 1    0.392150   0.343634   0.712065   0.647901    0.674375
Iteration 2    0.395873   0.318962   0.671246   0.677959    0.672940
Iteration 3    0.397316   0.367966   0.682865   0.589944    0.625685
Iteration 4    0.417803   0.336075   0.669237   0.705869    0.678971

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.354126   0.340108   0.732396   0.678674    0.701717
Iteration 1    0.327169   0.362472   0.681961   0.754683    0.712538
Iteration 2    0.333330   0.332577   0.722540   0.656653    0.684975
Iteration 3    0.334741   0.387780   0.667032   0.618705    0.631329
Iteration 4    0.344485   0.355181   0.731463   0.664969    0.690754

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.299904   0.350444   0.725197   0.729932    0.725954
Iteration 1    0.282658   0.359417   0.737796   0.691213    0.710470
Iteration 2    0.282050   0.354790   0.706997   0.720574    0.708427
Iteration 3    0.289986   0.378581   0.702266   0.660881    0.677527
Iteration 4    0.289369   0.361720   0.676536   0.697843    0.683398

