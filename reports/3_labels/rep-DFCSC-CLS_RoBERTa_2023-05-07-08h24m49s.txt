RESULTS REPORT - DFCSC-CLS
Model: RoBERTa
Encoder: roberta-base
Dataset: facts
Evaluation: test set (5 random seeds)
Max sequence length: 512
Min context length: 250
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 00h33m56s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    0.485329  0.011817  0.283824 0.013746   0.7363  0.1408   0.5900  0.0287   0.6198   0.0488
  2    0.316402  0.003327  0.282721 0.015166   0.8042  0.0328   0.6811  0.0535   0.7182   0.0272
  3    0.258226  0.006282  0.280910 0.020773   0.7740  0.0296   0.7445  0.0281   0.7550   0.0085
  4    0.223713  0.003931  0.281890 0.008099   0.7763  0.0135   0.7316  0.0094   0.7515   0.0052

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
Other: 2 
=> Iteration 0:
Epoch 1:
[[ 230    0  162]
 [   1    8   28]
 [  49    2 1717]]
Epoch 2:
[[ 279    0  113]
 [   1   11   25]
 [  77    3 1688]]
Epoch 3:
[[ 318    1   73]
 [   1   23   13]
 [ 114   20 1634]]
Epoch 4:
[[ 287    0  105]
 [   1   19   17]
 [  85   13 1670]]
=> Iteration 1:
Epoch 1:
[[ 267    0  125]
 [   1    6   30]
 [  69    1 1698]]
Epoch 2:
[[ 231    0  161]
 [   1   11   25]
 [  52    3 1713]]
Epoch 3:
[[ 309    0   83]
 [   1   17   19]
 [  98   10 1660]]
Epoch 4:
[[ 292    1   99]
 [   1   19   17]
 [  87   13 1668]]
=> Iteration 2:
Epoch 1:
[[ 322    0   70]
 [   5    0   32]
 [ 129    0 1639]]
Epoch 2:
[[ 316    1   75]
 [   1   20   16]
 [ 116   12 1640]]
Epoch 3:
[[ 277    0  115]
 [   1   17   19]
 [  75    8 1685]]
Epoch 4:
[[ 280    0  112]
 [   1   18   18]
 [  77    9 1682]]
=> Iteration 3:
Epoch 1:
[[ 258    0  134]
 [   1    0   36]
 [  52    0 1716]]
Epoch 2:
[[ 251    0  141]
 [   1   12   24]
 [  53    4 1711]]
Epoch 3:
[[ 291    0  101]
 [   1   19   17]
 [  82    7 1679]]
Epoch 4:
[[ 296    0   96]
 [   1   20   16]
 [  85   13 1670]]
=> Iteration 4:
Epoch 1:
[[ 286    0  106]
 [   3    8   26]
 [  90    1 1677]]
Epoch 2:
[[ 328    0   64]
 [   3   16   18]
 [ 131    9 1628]]
Epoch 3:
[[ 302    2   88]
 [   1   22   14]
 [ 101   16 1651]]
Epoch 4:
[[ 297    0   95]
 [   1   18   18]
 [  87    9 1672]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.475296   0.296384   0.840599   0.591368    0.653124
Iteration 1    0.479284   0.264270   0.855260   0.601231    0.647700
Iteration 2    0.478211   0.301452   0.549184   0.582822    0.564534
Iteration 3    0.485941   0.274187   0.579815   0.542917    0.557747
Iteration 4    0.507912   0.282829   0.856846   0.631446    0.675792

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.315390   0.276321   0.830551   0.654594    0.705236
Iteration 1    0.312857   0.311643   0.833716   0.618491    0.683028
Iteration 2    0.313529   0.277529   0.761094   0.758088    0.758300
Iteration 3    0.318403   0.280963   0.828333   0.644130    0.704046
Iteration 4    0.321834   0.267148   0.767334   0.729994    0.740150

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.255017   0.289149   0.735713   0.785685    0.758579
Iteration 1    0.253285   0.279278   0.776365   0.728880    0.748087
Iteration 2    0.256013   0.288414   0.797012   0.706382    0.743838
Iteration 3    0.256197   0.242781   0.814393   0.735174    0.768300
Iteration 4    0.270618   0.304928   0.746446   0.766275    0.756008

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.226061   0.279729   0.765036   0.730076    0.746418
Iteration 1    0.219179   0.280871   0.759719   0.733950    0.746174
Iteration 2    0.218960   0.286473   0.792349   0.717377    0.749610
Iteration 3    0.225677   0.268935   0.772693   0.746738    0.759044
Iteration 4    0.228687   0.293443   0.791597   0.729947    0.756052

