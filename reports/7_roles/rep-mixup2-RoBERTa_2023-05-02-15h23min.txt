RESULTS REPORT (MIXUP 2 SINGLE SENTENCE CLASSIFICATION)
Model: RoBERTa
Encoder: roberta-base
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate : 1e-05
Number of epochs: 4
Mixup alpha: 0.1
Augmentation rate: 0.5
Classes to augment: ['Argument', 'Statute', 'Precedent', 'RulingByLowerCourt', 'RulingByPresentCourt']
Average number of mixup vectors by epoch: 3583.0
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h44m26s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.427994  0.020024  1.164055 0.038539   0.6105  0.0296   0.5168  0.0403   0.5356   0.0348
  2    1.156663  0.004569  1.130807 0.039195   0.5973  0.0201   0.5603  0.0177   0.5623   0.0276
  3    1.042932  0.003901  1.133427 0.024176   0.5806  0.0211   0.5726  0.0069   0.5689   0.0100
  4    0.971056  0.002524  1.134868 0.009866   0.5827  0.0073   0.5810  0.0117   0.5753   0.0090

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[306  10   3  13   6   2  52]
 [ 43 183   4  42   1   0  43]
 [ 23   9 130   6   0   1  32]
 [ 59  13  17 191   3   3 115]
 [ 55   6   2  16  13   7  23]
 [ 10   0   0   4   2  15   6]
 [ 96  41  11  77   1   6 393]]
Epoch 2:
[[270  16   5   6  21   4  70]
 [ 23 213   3  27   1   0  49]
 [  8   6 136   4   2   0  45]
 [ 44  26  17 171   6   0 137]
 [ 33  11   1  13  28   6  30]
 [  2   0   0   2   3  18  12]
 [ 50  48  14  53  10   5 445]]
Epoch 3:
[[291  16   2   5  21   5  52]
 [ 27 214  10  22   3   1  39]
 [ 13  12 137   6   0   1  32]
 [ 52  15  20 201   6   1 106]
 [ 38  12   1   8  31  10  22]
 [  2   0   0   4   2  24   5]
 [ 65  63  24  74  13  14 372]]
Epoch 4:
[[290  14   3   6  17   5  57]
 [ 26 209   6  27   2   1  45]
 [ 10  13 133   5   0   1  39]
 [ 47  21  16 202   6   0 109]
 [ 34  12   1  10  31  11  23]
 [  2   0   0   4   1  24   6]
 [ 56  76  16  80  12  12 373]]
=> Iteration 1:
Epoch 1:
[[268   8   0   8  13   3  92]
 [ 26 193   3  20   2   0  72]
 [  3   2 125   1   0   0  70]
 [ 45  15  13 169   5   0 154]
 [ 33   8   1   8  26   2  44]
 [  6   0   1   2   0  12  16]
 [ 45  18   8  50   8   2 494]]
Epoch 2:
[[290  17   2  10  16   3  54]
 [ 28 215   4  28   1   0  40]
 [  8   7 142   4   0   0  40]
 [ 51  17  20 198   6   2 107]
 [ 33  15   3  11  28   6  26]
 [  5   0   1   4   0  19   8]
 [ 60  62  12  83   7   7 394]]
Epoch 3:
[[288  15   2   4  23   4  56]
 [ 25 212   5  22   3   0  49]
 [ 10   4 128   5   0   1  53]
 [ 45  11  13 196   8   1 127]
 [ 31  15   0   7  34   7  28]
 [  2   0   0   2   3  19  11]
 [ 65  50   4  64  15   7 420]]
Epoch 4:
[[280  17   6   7  21   5  56]
 [ 22 215   7  27   2   1  42]
 [  7  11 142   4   0   1  36]
 [ 46  14  18 208   7   1 107]
 [ 27  15   2  10  36   9  23]
 [  1   0   0   4   1  25   6]
 [ 48  71  14  77  11  11 393]]
=> Iteration 2:
Epoch 1:
[[174  28   3  11   2   3 171]
 [  4 179   1  28   0   0 104]
 [  1   6 116   5   0   0  73]
 [ 26  14   8 172   2   0 179]
 [ 14  12   1  14   4   1  76]
 [  2   0   1   0   0   9  25]
 [ 24  30   3  55   0   2 511]]
Epoch 2:
[[260  15   7   3  25   8  74]
 [ 21 202   7  21   5   1  59]
 [  7   4 145   3   0   1  41]
 [ 42  12  22 169  10   3 143]
 [ 28  11   5   7  34  11  26]
 [  1   0   0   0   3  22  11]
 [ 49  41  17  48  11  13 446]]
Epoch 3:
[[279  22   6  16  26   3  40]
 [ 27 217   6  33   6   1  26]
 [  9  10 140   5   0   1  36]
 [ 44  21  16 213  10   1  96]
 [ 31  16   3  19  30   9  14]
 [  2   0   0   2   1  22  10]
 [ 68 102  11  96  26  12 310]]
Epoch 4:
[[263  18   6  18  21   3  63]
 [ 21 209   6  30   4   1  45]
 [  9   8 138   5   0   0  41]
 [ 38  16  14 216   7   1 109]
 [ 27  14   2  21  28  10  20]
 [  1   0   0   2   1  21  12]
 [ 52  61   7  94  12  11 388]]
=> Iteration 3:
Epoch 1:
[[241  36   4  11  12   7  81]
 [ 18 231   2  24   0   0  41]
 [  6   8 133   8   0   0  46]
 [ 33  30  19 196   6   1 116]
 [ 27  21   4  23  15   8  24]
 [  4   2   0   2   0  17  12]
 [ 52  80   8  81   1   5 398]]
Epoch 2:
[[245  17   6   3  19   4  98]
 [ 17 218   4  17   2   0  58]
 [  5   4 133   7   0   0  52]
 [ 42  15  11 181   5   0 147]
 [ 28  16   1   5  29   9  34]
 [  0   0   1   0   0  21  15]
 [ 40  36   6  55   6   4 478]]
Epoch 3:
[[289  25   3   8  14   5  48]
 [ 25 219   5  24   4   1  38]
 [  7  10 135   5   0   0  44]
 [ 49  21  16 191   6   0 118]
 [ 35  16   1  11  28  10  21]
 [  1   0   0   4   5  22   5]
 [ 73  71  13  77   4  12 375]]
Epoch 4:
[[285  13   3   7  19   6  59]
 [ 28 203   6  24   4   1  50]
 [  7   8 141   7   0   0  38]
 [ 47  16  16 205   7   0 110]
 [ 33  14   1  11  27  10  26]
 [  1   0   0   4   3  22   7]
 [ 63  44  15  91   6  10 396]]
=> Iteration 4:
Epoch 1:
[[287   5   7   8  10   6  69]
 [ 31 193   5  30   5   0  52]
 [  4   4 129   5   0   1  58]
 [ 48  11  13 184   8   0 137]
 [ 40   4   3   6  28   9  32]
 [  4   0   0   0   0  21  12]
 [ 66  18   5  64   5   8 459]]
Epoch 2:
[[278  46   6  15   2   5  40]
 [ 24 231   6  33   0   0  22]
 [  3  25 133   8   0   1  31]
 [ 47  30  14 231   3   0  76]
 [ 37  26   2  18  10   9  20]
 [  4   0   0   4   0  20   9]
 [ 44 200   7 118   0  11 245]]
Epoch 3:
[[278   2   3  11  21   5  72]
 [ 31 185   5  40   5   1  49]
 [ 10   3 131   9   0   1  47]
 [ 43   9  14 219   8   1 107]
 [ 36   6   1  13  27  10  29]
 [  2   0   0   4   1  22   8]
 [ 50  23   3 108  11  11 419]]
Epoch 4:
[[281  11   4   8  20   4  64]
 [ 20 217   8  30   4   1  36]
 [  8   6 137   7   0   1  42]
 [ 44  17  17 211   8   2 102]
 [ 34  12   3  15  24  10  24]
 [  2   0   0   4   1  23   7]
 [ 50  63  13  96  10   9 384]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.435642   1.184075   0.582019   0.517652    0.525573
Iteration 1    1.425497   1.128428   0.648632   0.523658    0.560314
Iteration 2    1.461057   1.227080   0.628566   0.444286    0.477343
Iteration 3    1.401244   1.158510   0.570293   0.530784    0.534637
Iteration 4    1.416532   1.122181   0.623161   0.567860    0.579900

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.158261   1.094865   0.598624   0.556267    0.569673
Iteration 1    1.151497   1.090211   0.599846   0.570547    0.576949
Iteration 2    1.160085   1.151726   0.578623   0.576033    0.566650
Iteration 3    1.151104   1.121490   0.632663   0.571144    0.589051
Iteration 4    1.162366   1.195744   0.576754   0.527494    0.509264

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.044502   1.126235   0.572003   0.585764    0.570875
Iteration 1    1.039957   1.105640   0.607295   0.570768    0.582404
Iteration 2    1.037469   1.177484   0.546348   0.566090    0.552020
Iteration 3    1.043985   1.136511   0.580338   0.571762    0.565975
Iteration 4    1.048747   1.121264   0.597154   0.568401    0.573049

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.968775   1.134149   0.580007   0.580881    0.571789
Iteration 1    0.973904   1.122608   0.595858   0.602771    0.592948
Iteration 2    0.970631   1.148351   0.577275   0.567915    0.567964
Iteration 3    0.967955   1.125843   0.584697   0.575952    0.573295
Iteration 4    0.974013   1.143390   0.575447   0.577724    0.570740

