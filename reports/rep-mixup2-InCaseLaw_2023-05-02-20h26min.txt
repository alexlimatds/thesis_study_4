RESULTS REPORT (MIXUP 2 SINGLE SENTENCE CLASSIFICATION)
Model: InCaseLaw
Encoder: law-ai/InCaseLawBERT
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate : 1e-05
Number of epochs: 4
Mixup alpha: 0.1
Augmentation rate: 1.0
Classes to augment: ['Precedent', 'RulingByLowerCourt']
Average number of mixup vectors by epoch: 2811.5
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h46m08s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.259706  0.012426  1.006186 0.007074   0.6357  0.0157   0.5988  0.0096   0.6008   0.0099
  2    1.008825  0.007824  1.020205 0.015220   0.6336  0.0165   0.6066  0.0048   0.6031   0.0109
  3    0.906489  0.007546  1.042607 0.019940   0.6227  0.0102   0.6070  0.0051   0.6014   0.0069
  4    0.840401  0.004266  1.057697 0.011205   0.6150  0.0056   0.6088  0.0025   0.6013   0.0031

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[259   8   4   4  11   4 102]
 [ 13 208   2  28   1   0  64]
 [  3   1 122  12   0   0  63]
 [ 35   9   9 239   5   0 104]
 [ 23   7   2  13  23  11  43]
 [  1   0   0   2   0  24  10]
 [ 30  17   5 118   1   6 448]]
Epoch 2:
[[291  13   0   5  16   4  63]
 [ 15 223   1  28   2   1  46]
 [  8   2 120   9   0   0  62]
 [ 35   8   6 229   6   0 117]
 [ 29   9   1   8  30  12  33]
 [  1   0   0   3   0  24   9]
 [ 38  33   4  92   3  11 444]]
Epoch 3:
[[304  13   3   3  18   3  48]
 [ 19 225   2  29   2   1  38]
 [  7   3 133  10   0   0  48]
 [ 33  10  12 241   5   0 100]
 [ 28  10   1  13  28  11  31]
 [  1   1   0   2   0  25   8]
 [ 55  50   7 115   7  11 380]]
Epoch 4:
[[291  15   7   6  20   3  50]
 [ 19 225   2  28   2   1  39]
 [  6   4 133   8   0   0  50]
 [ 33  11   9 233   6   0 109]
 [ 27  10   2  11  30  12  30]
 [  1   1   0   2   0  26   7]
 [ 45  63   7 109   9  11 381]]
=> Iteration 1:
Epoch 1:
[[320   9   5   6   6   4  42]
 [ 26 213   5  28   1   0  43]
 [  8   2 140  14   0   0  37]
 [ 45  11  12 240   3   0  90]
 [ 38   5   3  14  15  14  33]
 [  2   1   0   0   0  24  10]
 [ 65  57  11 107   1   9 375]]
Epoch 2:
[[323   6   4  10  12   3  34]
 [ 23 213   6  42   2   1  29]
 [ 10   2 141  22   0   0  26]
 [ 37   7  12 281   4   0  60]
 [ 32   5   8  26  18  14  19]
 [  1   0   0   2   0  26   8]
 [ 61  37  15 202   6  11 293]]
Epoch 3:
[[324   9   1   9  12   3  34]
 [ 25 221   4  33   2   1  30]
 [ 11   2 134  15   0   0  39]
 [ 40   9  10 239   6   0  97]
 [ 34   8   1  14  25  13  27]
 [  1   1   0   2   0  25   8]
 [ 68  65   6 118   9   9 350]]
Epoch 4:
[[317  10   1   7  14   3  40]
 [ 23 222   5  30   2   1  33]
 [ 10   2 135  14   0   0  40]
 [ 36   9   9 229   7   0 111]
 [ 31  11   2  14  26  14  24]
 [  1   1   0   2   0  26   7]
 [ 54  74   8 103  13  11 362]]
=> Iteration 2:
Epoch 1:
[[294  11   4   8  15   4  56]
 [ 15 216   4  37   3   0  41]
 [ 10   2 140  15   0   0  34]
 [ 36   7  16 259   8   0  75]
 [ 25   7   5  22  27  13  23]
 [  1   1   0   0   0  24  11]
 [ 49  31  18 157   3   5 362]]
Epoch 2:
[[304  13   2   8  10   3  52]
 [ 19 216   4  28   2   0  47]
 [ 10   3 137   8   0   0  43]
 [ 40  10  10 215   4   0 122]
 [ 31   8   2  15  27  12  27]
 [  1   1   0   0   0  25  10]
 [ 44  47   9  91   5  11 418]]
Epoch 3:
[[317  15   4   8   9   3  36]
 [ 23 226   2  35   3   1  26]
 [ 10   4 136  14   0   0  37]
 [ 39  11  12 248   5   0  86]
 [ 35  14   3  14  25  14  17]
 [  1   1   0   2   0  26   7]
 [ 71  80  14 116   5  12 327]]
Epoch 4:
[[301  15   1   6  17   3  49]
 [ 19 222   2  31   3   0  39]
 [  9   5 133   9   0   0  45]
 [ 37  13   9 221   6   0 115]
 [ 31  12   2  11  30  12  24]
 [  1   1   0   2   0  26   7]
 [ 58  67  12  90   7  11 380]]
=> Iteration 3:
Epoch 1:
[[295   9   7   9  10   4  58]
 [ 23 211   6  34   2   0  40]
 [  6   2 137  11   0   0  45]
 [ 38   8  11 241   3   0 100]
 [ 35   3   5   8  31  12  28]
 [  1   0   0   2   1  24   9]
 [ 50  24  10 124   1   7 409]]
Epoch 2:
[[297  22   0   6  10   3  54]
 [ 20 226   3  31   1   1  34]
 [  7   5 127  10   0   0  52]
 [ 37  14  10 215   4   0 121]
 [ 36  15   1   7  27  13  23]
 [  1   0   0   0   0  27   9]
 [ 42  67   5  92   4  11 404]]
Epoch 3:
[[289  20   3   7  13   3  57]
 [ 20 225   2  25   2   0  42]
 [  7   5 130   7   0   0  52]
 [ 32  14   9 206   5   0 135]
 [ 28  10   1  14  24  12  33]
 [  1   0   0   2   0  26   8]
 [ 48  51   7  79   3   7 430]]
Epoch 4:
[[303  14   3   5  16   3  48]
 [ 24 223   3  30   2   1  33]
 [  7   5 133  11   0   0  45]
 [ 37  10  12 222   5   0 115]
 [ 33   9   2  13  28  13  24]
 [  1   0   0   2   0  27   7]
 [ 52  55   7  98   5  11 397]]
=> Iteration 4:
Epoch 1:
[[263  13   2   5  22   4  83]
 [ 13 217   4  31   2   1  48]
 [  6   3 135   9   0   0  48]
 [ 26  11  11 221  11   1 120]
 [ 19  10   2  14  30  14  33]
 [  1   0   0   2   0  26   8]
 [ 28  29   7 100   4  13 444]]
Epoch 2:
[[316  10   0   4   8   3  51]
 [ 23 220   5  29   2   1  36]
 [  8   3 137   6   0   0  47]
 [ 37   9  11 216   5   0 123]
 [ 31   8   2   9  26  13  33]
 [  1   0   0   2   0  26   8]
 [ 48  45   7  88   7  10 420]]
Epoch 3:
[[309  15   0   6  11   3  48]
 [ 21 224   4  28   2   1  36]
 [ 11   3 135   7   0   0  45]
 [ 37  12  12 214   5   0 121]
 [ 29  10   2   9  29  15  28]
 [  1   0   0   2   0  26   8]
 [ 43  54   7  87  10  10 414]]
Epoch 4:
[[311  15   0   6  11   3  46]
 [ 22 224   4  29   2   1  34]
 [  9   4 138   9   0   0  41]
 [ 37  11  11 229   5   0 108]
 [ 32  11   2  11  24  14  28]
 [  1   1   0   2   0  26   7]
 [ 46  59   7 103  14  11 385]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.242826   1.013153   0.656680   0.582270    0.599168
Iteration 1    1.270012   1.006991   0.624955   0.593857    0.584166
Iteration 2    1.247082   1.013605   0.620447   0.603587    0.602268
Iteration 3    1.264987   1.002500   0.652823   0.608573    0.615004
Iteration 4    1.273621   0.994680   0.623483   0.605628    0.603448

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.008427   1.010636   0.650719   0.603012    0.611252
Iteration 1    1.020113   1.044549   0.602367   0.602759    0.582990
Iteration 2    0.995613   1.017762   0.637194   0.606085    0.606632
Iteration 3    1.009186   1.028039   0.635070   0.605469    0.601359
Iteration 4    1.010785   1.000040   0.642834   0.615770    0.613512

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.905911   1.025651   0.623620   0.609058    0.606410
Iteration 1    0.917257   1.053795   0.615994   0.604167    0.597313
Iteration 2    0.893726   1.075716   0.607441   0.607108    0.590428
Iteration 3    0.906708   1.036199   0.636256   0.599597    0.602874
Iteration 4    0.908841   1.021675   0.630351   0.615034    0.609918

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.839782   1.051175   0.614574   0.607902    0.602706
Iteration 1    0.844079   1.062347   0.606123   0.606991    0.596193
Iteration 2    0.832363   1.077330   0.615624   0.605687    0.600657
Iteration 3    0.842680   1.052010   0.623854   0.612629    0.605608
Iteration 4    0.843100   1.045623   0.614761   0.610756    0.601432

