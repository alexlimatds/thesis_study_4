RESULTS REPORT (SINGLE SENTENCE CLASSIFICATION)
Model: InCaseLaw
Encoder: law-ai/InCaseLawBERT
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Freeze layers: True
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 01h00m16s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.891335  0.049439  1.790906 0.020410   0.1357  0.0277   0.1599  0.0132   0.1139   0.0218
  2    1.786437  0.017602  1.749001 0.012380   0.1673  0.0558   0.1694  0.0125   0.1215   0.0159
  3    1.756447  0.014617  1.733021 0.010257   0.1760  0.0574   0.1751  0.0110   0.1249   0.0131
  4    1.746448  0.012824  1.728447 0.009632   0.1776  0.0568   0.1769  0.0113   0.1259   0.0133

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[132   0   0   0   0   0 260]
 [ 68   1   0   4   0   0 243]
 [ 56   0   0   3   0   0 142]
 [102   0   0   1   0   0 298]
 [ 27   0   0   0   0   0  95]
 [  6   0   0   0   0   0  31]
 [224   1   0   2   0   0 398]]
Epoch 2:
[[166   5   0   0   0   0 221]
 [ 88   4   0   6   0   0 218]
 [ 64   0   0   3   0   0 134]
 [113   3   0   1   0   0 284]
 [ 36   0   0   0   0   0  86]
 [  9   0   0   1   0   0  27]
 [244  10   0   5   0   0 366]]
Epoch 3:
[[186   7   0   0   0   0 199]
 [ 95   5   0   6   0   0 210]
 [ 63   0   0   3   0   0 135]
 [113   3   0   1   0   0 284]
 [ 38   0   0   0   0   0  84]
 [  9   0   0   2   0   0  26]
 [241  11   0   5   0   0 368]]
Epoch 4:
[[189   6   0   0   0   0 197]
 [ 97   5   0   6   0   0 208]
 [ 64   0   0   3   0   0 134]
 [116   3   0   1   0   0 281]
 [ 40   0   0   0   0   0  82]
 [  9   0   0   2   0   0  26]
 [241  11   0   5   0   0 368]]
=> Iteration 1:
Epoch 1:
[[ 32  59   0   3   0   0 298]
 [ 26  27   0   0   0   0 263]
 [  4  30   0   1   1   0 165]
 [ 20  49   0   0   0   0 332]
 [ 10  11   0   0   0   0 101]
 [  1   6   0   0   0   0  30]
 [ 25  23   0   0   0   0 577]]
Epoch 2:
[[147  33   0   2   0   0 210]
 [114  15   0   0   0   0 187]
 [ 39  18   1   2   1   0 140]
 [ 96  29   0   1   0   0 275]
 [ 47   5   0   0   0   0  70]
 [  9   3   0   0   0   0  25]
 [123  12   0   1   0   0 489]]
Epoch 3:
[[208  24   0   2   0   0 158]
 [149  11   0   0   0   0 156]
 [ 52  15   1   3   0   0 130]
 [126  24   0   2   0   0 249]
 [ 61   3   0   0   0   0  58]
 [  9   3   0   0   0   0  25]
 [191  12   0   1   0   0 421]]
Epoch 4:
[[219  22   0   2   0   0 149]
 [158  10   0   0   0   0 148]
 [ 55  15   1   3   0   0 127]
 [131  24   0   2   0   0 244]
 [ 63   2   0   0   0   0  57]
 [ 10   3   0   0   0   0  24]
 [200  10   0   1   0   0 414]]
=> Iteration 2:
Epoch 1:
[[289   0   0   5   0   0  98]
 [167   0   0   4   0   0 145]
 [ 81   0   0   0   0   0 120]
 [251   0   0   4   0   0 146]
 [ 77   0   0   3   0   0  42]
 [ 31   0   0   0   0   0   6]
 [392   0   0   5   0   0 228]]
Epoch 2:
[[283   2   0   5   0   0 102]
 [143   2   0   4   0   0 167]
 [ 73   1   0   0   0   0 127]
 [201   3   0   5   0   0 192]
 [ 70   0   0   1   0   0  51]
 [ 29   0   0   0   0   0   8]
 [347   3   0   4   0   0 271]]
Epoch 3:
[[279   4   0   4   0   0 105]
 [140   5   0   4   0   0 167]
 [ 69   2   0   0   0   0 130]
 [189   6   0   6   0   0 200]
 [ 70   1   0   1   0   0  50]
 [ 29   0   0   0   0   0   8]
 [319   3   0   4   0   0 299]]
Epoch 4:
[[281   6   0   2   0   0 103]
 [139   5   0   4   0   0 168]
 [ 67   2   0   0   0   0 132]
 [183   6   0   6   0   0 206]
 [ 67   2   0   1   0   0  52]
 [ 27   0   0   0   0   0  10]
 [314   3   0   4   0   0 304]]
=> Iteration 3:
Epoch 1:
[[212   9   0  36   0   0 135]
 [136  25   0  33   0   0 122]
 [ 61  37   0   7   0   0  96]
 [122  36   0  66   0   0 177]
 [ 52  12   0   8   0   0  50]
 [  9   2   0   8   0   0  18]
 [231  34   0  60   0   0 300]]
Epoch 2:
[[210   7   0   9   0   0 166]
 [124  22   0  11   0   0 159]
 [ 50  30   0   2   0   0 119]
 [102  34   0  30   0   0 235]
 [ 46   8   0   2   0   0  66]
 [ 10   0   0   1   0   0  26]
 [205  27   0  22   0   0 371]]
Epoch 3:
[[209   7   0   6   0   0 170]
 [109  21   0   8   0   0 178]
 [ 44  27   0   1   0   0 129]
 [ 93  29   0  22   0   0 257]
 [ 45   8   0   1   0   0  68]
 [ 10   0   0   1   0   0  26]
 [184  26   0  15   0   0 400]]
Epoch 4:
[[210   7   0   6   0   0 169]
 [106  23   0   8   0   0 179]
 [ 44  27   0   1   0   0 129]
 [ 91  29   0  21   0   0 260]
 [ 45   8   0   1   0   0  68]
 [ 10   0   0   1   0   0  26]
 [182  26   0  14   0   0 403]]
=> Iteration 4:
Epoch 1:
[[288  27   6  27   0   0  44]
 [181  32   0  63   0   0  40]
 [154  13   2  25   0   0   7]
 [264  28   2  61   0   0  46]
 [101   5   0   6   0   0  10]
 [ 21   2   0  10   0   0   4]
 [361  69   1  97   0   1  96]]
Epoch 2:
[[285  17   0   6   0   0  84]
 [167  21   0  22   0   0 106]
 [153   9   0   8   0   0  31]
 [239  15   0  14   0   0 133]
 [ 92   1   0   0   0   0  29]
 [ 20   2   0   0   0   0  15]
 [316  31   0  17   0   0 261]]
Epoch 3:
[[266  12   0   3   0   0 111]
 [134  17   0  12   0   0 153]
 [145   6   0   5   0   0  45]
 [202  13   0   8   0   0 178]
 [ 85   1   0   0   0   0  36]
 [ 18   2   0   0   0   0  17]
 [261  21   0  11   0   0 332]]
Epoch 4:
[[263  11   0   3   0   0 115]
 [126  16   0  11   0   0 163]
 [144   5   0   3   0   0  49]
 [200  11   0   7   0   0 183]
 [ 84   1   0   0   0   0  37]
 [ 18   2   0   0   0   0  17]
 [246  19   0  10   0   0 350]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.873208   1.806629   0.155134   0.139885    0.093402
Iteration 1    1.940386   1.807808   0.104232   0.155754    0.101683
Iteration 2    1.821424   1.756714   0.100757   0.158860    0.098058
Iteration 3    1.867018   1.777909   0.150816   0.180646    0.151762
Iteration 4    1.954639   1.805467   0.167656   0.164519    0.124692

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.790850   1.762815   0.106975   0.146317    0.100044
Iteration 1    1.810317   1.760509   0.271863   0.173191    0.124625
Iteration 2    1.755810   1.728830   0.141018   0.167762    0.107902
Iteration 3    1.784550   1.743040   0.166783   0.181964    0.144755
Iteration 4    1.790656   1.749808   0.149688   0.178001    0.130123

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.761352   1.744212   0.111796   0.154515    0.106050
Iteration 1    1.776831   1.743882   0.283226   0.178426    0.126557
Iteration 2    1.731856   1.716895   0.160066   0.174417    0.115860
Iteration 3    1.759542   1.728437   0.173180   0.184926    0.144301
Iteration 4    1.752655   1.731678   0.151628   0.183360    0.131644

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.755950   1.738748   0.113253   0.155608    0.106645
Iteration 1    1.757648   1.738847   0.283460   0.180383    0.127028
Iteration 2    1.724042   1.713261   0.161962   0.176289    0.117205
Iteration 3    1.754480   1.724318   0.175332   0.186524    0.145811
Iteration 4    1.740122   1.727062   0.154037   0.185573    0.132587

