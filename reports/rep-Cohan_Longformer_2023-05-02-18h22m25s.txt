RESULTS REPORT
Model: Longformer
Encoder: allenai/longformer-base-4096
Chunk layout: Cohan
Evaluation: test set (5 random seeds)
Max sequence length: 1024
Max sentence length: 85
Max sentences per chunk: 7
Batch size: 4
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h49m17s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.352850  0.018944  0.963992 0.094603   0.6712  0.0681   0.5605  0.0394   0.5738   0.0395
  2    0.967479  0.010401  0.895625 0.065579   0.7191  0.0134   0.6099  0.0267   0.6302   0.0232
  3    0.803008  0.017504  0.895493 0.032122   0.7041  0.0210   0.6350  0.0187   0.6501   0.0155
  4    0.683477  0.018468  0.865992 0.025562   0.7109  0.0123   0.6617  0.0090   0.6782   0.0078

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[302   3   4  19  10   2  52]
 [  4 248   1  36   2   0  25]
 [  2   4 131  18   0   0  46]
 [ 21   6   1 307  16   0  50]
 [ 23   0   0  38  17   7  37]
 [  2   2   0   3   0  13  17]
 [ 36   9   2 153   0   4 421]]
Epoch 2:
[[316   5   8   2   1   1  59]
 [  8 273   1  11   0   0  23]
 [  0   7 129   2   0   1  62]
 [ 33  12   0 224   8   3 121]
 [ 42   8   0  10  26  16  20]
 [  4   1   0   0   0  20  12]
 [ 16  25   1  67   0  14 502]]
Epoch 3:
[[313  20  13  13   9   0  24]
 [  2 290   2  10   0   0  12]
 [  5   6 148   9   1   0  32]
 [ 24  17   0 302  10   0  48]
 [ 32  15   0  23  42   4   6]
 [  4   3   0   1   2  18   9]
 [ 25  48   7 127  12   6 400]]
Epoch 4:
[[321   4  10   5   7   1  44]
 [  6 281   2   7   1   0  19]
 [  1   5 149   4   0   1  41]
 [ 29  14   1 258  10   1  88]
 [ 34  11   0  16  43   8  10]
 [  4   1   0   0   0  19  13]
 [ 17  36   6  77   0  10 479]]
=> Iteration 1:
Epoch 1:
[[340   2   0   3   2   0  45]
 [ 28 243   0  20   0   0  25]
 [  1   6  75   8   0   0 111]
 [ 40   9   0 240   5   0 107]
 [ 54   3   0  19  14   0  32]
 [  5   3   0   4   0   1  24]
 [ 51  14   0  87   0   0 473]]
Epoch 2:
[[326   6  12   2   0   0  46]
 [  8 278   0   6   0   0  24]
 [  0   8 128   0   0   0  65]
 [ 35  32   0 208   7   0 119]
 [ 56  20   0   3  12   1  30]
 [  6   3   0   0   0   8  20]
 [ 29  48   0  74   0   0 474]]
Epoch 3:
[[280   2  17  18  24   0  51]
 [  4 267   2  23   3   0  17]
 [  0   3 149   9   0   0  40]
 [ 29  10   2 310  10   0  40]
 [ 28   8   0  29  30   7  20]
 [  4   3   0   1   2  15  12]
 [ 14  22  12 145   0   5 427]]
Epoch 4:
[[311   4  13   3  16   0  45]
 [ 17 271   2   6   0   0  20]
 [  0   5 144   2   0   0  50]
 [ 33  12   1 241   9   0 105]
 [ 39  10   0   6  44  10  13]
 [  4   3   0   0   2  17  11]
 [ 17  34   8  90   2   7 467]]
=> Iteration 2:
Epoch 1:
[[340   2   7   5   0   0  38]
 [ 18 261   0  14   0   0  23]
 [  0   9 116   8   2   0  66]
 [ 37   9   1 265   8   0  81]
 [ 66   5   0  17  11   2  21]
 [  4   5   0   1   2  10  15]
 [ 66  34   1 110   0   0 414]]
Epoch 2:
[[285   2  13   5   7   1  79]
 [ 10 252   1  15   2   0  36]
 [  0   4 126   6   0   0  65]
 [ 31  12   1 275   8   0  74]
 [ 28   2   0  26  26   4  36]
 [  2   1   0   1   0  17  16]
 [  8  18   2 112   0   1 484]]
Epoch 3:
[[298   7  17  10  10   0  50]
 [  5 272   1  19   2   0  17]
 [  0   5 133  15   0   0  48]
 [ 28  12   2 311  10   0  38]
 [ 36   4   0  25  30   7  20]
 [  4   1   0   1   0  19  12]
 [ 19  20   3 165   0  10 408]]
Epoch 4:
[[311   2  16   3  16   0  44]
 [ 11 273   2   8   2   0  20]
 [  0   4 140   4   0   0  53]
 [ 32  12   4 252   7   1  93]
 [ 48   4   0  13  41   4  12]
 [  4   1   0   0   0  20  12]
 [ 21  25   7  80   3   7 482]]
=> Iteration 3:
Epoch 1:
[[314   7   8   4   0   0  59]
 [ 15 265   0  14   0   0  22]
 [  0  11 111   4   0   0  75]
 [ 31  19   0 246   0   2 103]
 [ 49  13   0  14   0   5  41]
 [  5   3   0   0   0  11  18]
 [ 39 112   0  68   0   6 400]]
Epoch 2:
[[315  10  12   3   3   0  49]
 [  8 277   1  13   0   0  17]
 [  0   7 133   3   0   0  58]
 [ 31  22   0 223   7   2 116]
 [ 48   6   0   7  21  10  30]
 [  1   3   0   0   0  23  10]
 [ 26  37   5  62   0  10 485]]
Epoch 3:
[[330   3  12   4   3   0  40]
 [ 15 262   2  16   0   0  21]
 [  0   3 138   6   0   0  54]
 [ 35  10   0 289   2   0  65]
 [ 63   2   0  20  14   1  22]
 [  4   1   0   1   0  16  15]
 [ 56  41   6 109   0   4 409]]
Epoch 4:
[[314   7  14   3  15   0  39]
 [ 10 270   2  13   0   0  21]
 [  1   4 147   4   0   0  45]
 [ 32  15   4 252   7   1  90]
 [ 43   5   0  11  44   7  12]
 [  4   1   0   0   1  20  11]
 [ 33  31  12  67   8   7 467]]
=> Iteration 4:
Epoch 1:
[[308   5  18   6   8   1  46]
 [  8 268   3  15   1   0  21]
 [  0   7 148   7   0   0  39]
 [ 24  14   4 246   9   0 104]
 [ 39   0   0  24  12  14  33]
 [  6   3   0   0   0  17  11]
 [ 21  28  12  97   0   6 461]]
Epoch 2:
[[294  13   7   5  14   0  59]
 [  3 278   1  14   1   0  19]
 [  0  10 122   5   0   0  64]
 [ 32  14   0 265   8   0  82]
 [ 39   8   0  17  29   1  28]
 [  6   3   0   0   0  13  15]
 [  6  43   0 108   0   4 464]]
Epoch 3:
[[342  12   7   3   4   0  24]
 [  4 287   1  10   0   0  14]
 [  1   6 135   5   0   0  54]
 [ 36  19   4 228   7   0 107]
 [ 51  10   0  17  30   2  12]
 [  4   3   0   0   0  18  12]
 [ 48  85   5  81   5   3 398]]
Epoch 4:
[[314   9  14   3  13   0  39]
 [  5 280   2   9   1   0  19]
 [  1   5 143   3   0   0  49]
 [ 35   9   4 245   7   0 101]
 [ 30   7   0  15  44   4  22]
 [  4   3   0   0   0  18  12]
 [ 19  51   6  74   3   4 468]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.342833   0.889154   0.670126   0.590977    0.613424
Iteration 1    1.386972   1.027466   0.771214   0.500936    0.517661
Iteration 2    1.330982   0.980342   0.706158   0.564870    0.587649
Iteration 3    1.346786   1.093481   0.565786   0.534661    0.536981
Iteration 4    1.356679   0.829516   0.642592   0.611289    0.613192

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.958706   0.809351   0.707235   0.632471    0.639697
Iteration 1    0.968183   1.000804   0.738057   0.562839    0.584449
Iteration 2    0.973325   0.846984   0.730215   0.612019    0.648106
Iteration 3    0.983198   0.900772   0.702830   0.638244    0.642840
Iteration 4    0.953981   0.920217   0.717184   0.604145    0.635890

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.780674   0.852240   0.705959   0.668054    0.678046
Iteration 1    0.802014   0.887937   0.674212   0.629727    0.644068
Iteration 2    0.810484   0.881622   0.689478   0.638633    0.650484
Iteration 3    0.831558   0.906076   0.734955   0.611400    0.630707
Iteration 4    0.790309   0.949592   0.715776   0.627155    0.647109

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.666127   0.817893   0.719635   0.675025    0.687007
Iteration 1    0.673587   0.868698   0.692480   0.647956    0.663688
Iteration 2    0.688488   0.877336   0.714228   0.661435    0.680506
Iteration 3    0.717334   0.872114   0.701489   0.666231    0.678516
Iteration 4    0.671850   0.893921   0.726503   0.657922    0.681507

