RESULTS REPORT (MIXUP 2 SINGLE SENTENCE CLASSIFICATION)
Model: InCaseLaw
Encoder: law-ai/InCaseLawBERT
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate : 1e-05
Number of epochs: 4
Mixup alpha: 0.1
Augmentation rate: 0.5
Classes to augment: ['Argument', 'Statute', 'Precedent', 'RulingByLowerCourt', 'RulingByPresentCourt']
Average number of mixup vectors by epoch: 3607.75
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h45m35s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.260501  0.014331  1.006726 0.008379   0.6298  0.0140   0.6008  0.0082   0.5992   0.0148
  2    1.008981  0.006232  1.031022 0.015559   0.6245  0.0206   0.6010  0.0104   0.5974   0.0108
  3    0.910487  0.006830  1.051675 0.017523   0.6142  0.0104   0.6046  0.0065   0.5939   0.0054
  4    0.843652  0.008320  1.060115 0.007416   0.6111  0.0053   0.6078  0.0030   0.5974   0.0036

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[267  12   5   9  12   4  83]
 [ 14 222   2  26   1   0  51]
 [  3   1 130  13   0   0  54]
 [ 34  10   9 249   5   0  94]
 [ 26   8   2  13  24  12  37]
 [  1   1   0   2   0  24   9]
 [ 36  24   6 133   1   8 417]]
Epoch 2:
[[279  29   0   9   7   3  65]
 [ 13 236   1  20   1   0  45]
 [  2   4 125   4   0   0  66]
 [ 33  13   7 206   5   0 137]
 [ 29  12   2  17  20  11  31]
 [  1   1   0   0   0  24  11]
 [ 42  66   5  68   1   7 436]]
Epoch 3:
[[303  19   5   7   8   3  47]
 [ 20 229   3  24   2   1  37]
 [  7   2 136  11   0   0  45]
 [ 35  11  12 234   4   0 105]
 [ 33  12   2  14  20  11  30]
 [  1   1   0   2   0  25   8]
 [ 55  75   7  93   3  10 382]]
Epoch 4:
[[284  25   4   5  22   3  49]
 [ 19 237   3  20   2   1  34]
 [  6   3 134  10   0   0  48]
 [ 33  16  10 229   6   1 106]
 [ 27  12   2  12  29  14  26]
 [  1   1   0   2   0  26   7]
 [ 46  94   9  90   6  13 367]]
=> Iteration 1:
Epoch 1:
[[320  12   4   6   4   5  41]
 [ 27 216   5  28   1   0  39]
 [  7   3 141  11   0   0  39]
 [ 43  11  15 238   3   0  91]
 [ 38  10   6  15  12  15  26]
 [  2   1   0   0   0  24  10]
 [ 64  65  12 111   1  11 361]]
Epoch 2:
[[274  41   5   2  18   4  48]
 [ 10 248   3  26   3   0  26]
 [  4   7 138  11   0   0  41]
 [ 32  21  13 237   7   0  91]
 [ 24  21   2   9  27  14  25]
 [  1   1   0   0   0  25  10]
 [ 31 151  14  98   4  10 317]]
Epoch 3:
[[329   8   1   8  10   3  33]
 [ 26 222   4  37   2   1  24]
 [ 11   3 132  14   0   1  40]
 [ 39  11   8 249   6   0  88]
 [ 37  11   1  18  23  14  18]
 [  1   1   0   2   0  26   7]
 [ 64  76  10 132   8  11 324]]
Epoch 4:
[[315  14   1   5  13   3  41]
 [ 23 226   4  29   2   1  31]
 [  8   3 136  14   0   1  39]
 [ 35  12  10 227   6   0 111]
 [ 31  12   1  11  28  14  25]
 [  1   1   0   2   0  26   7]
 [ 49  75   8  95  11  11 376]]
=> Iteration 2:
Epoch 1:
[[299  16   4   9  10   3  51]
 [ 15 224   3  33   2   0  39]
 [  9   2 135  13   0   0  42]
 [ 37   9  13 239   7   0  96]
 [ 25  12   5  17  26  13  24]
 [  1   1   0   0   0  24  11]
 [ 54  47  15 122   2   4 381]]
Epoch 2:
[[324   5   2   3  13   3  42]
 [ 26 225   4  16   2   0  43]
 [ 13   3 132   5   0   0  48]
 [ 43  25  12 188   5   0 128]
 [ 32  11   4  13  27  14  21]
 [  1   0   0   0   0  25  11]
 [ 72  58  13  57   4  11 410]]
Epoch 3:
[[301  23   1   6  17   3  41]
 [ 18 239   1  26   3   0  29]
 [ 12   8 131  11   0   0  39]
 [ 35  21  11 230   6   0  98]
 [ 26  15   3  13  30  14  21]
 [  1   1   0   2   0  26   7]
 [ 58 112  10 103   6  11 325]]
Epoch 4:
[[313  15   2   5  15   3  39]
 [ 22 229   2  26   2   0  35]
 [ 11   4 133  11   0   0  42]
 [ 37  16  11 223   6   0 108]
 [ 31  13   3  12  28  14  21]
 [  1   1   0   2   0  26   7]
 [ 62  74  13  93   7  11 365]]
=> Iteration 3:
Epoch 1:
[[292  10  10   8  11   4  57]
 [ 18 221   6  32   1   0  38]
 [  5   1 142  11   0   0  42]
 [ 38  12  12 235   4   0 100]
 [ 31   8   5   7  33  13  25]
 [  2   0   0   2   1  23   9]
 [ 44  38  11 124   1   6 401]]
Epoch 2:
[[275  16   2   9  15   3  72]
 [ 16 220   2  32   2   0  44]
 [  3   2 130  11   0   0  55]
 [ 34   9   9 229   6   0 114]
 [ 22  11   1  13  32  13  30]
 [  1   1   0   2   0  25   8]
 [ 33  43   3 112   4  10 420]]
Epoch 3:
[[309  14   4   6  16   3  40]
 [ 23 228   5  31   3   1  25]
 [  8   4 135  13   0   0  41]
 [ 37  12  13 238   5   0  96]
 [ 33  11   4   9  30  13  22]
 [  1   0   0   2   0  27   7]
 [ 60  68   9 113   9  11 355]]
Epoch 4:
[[303  15   3   6  15   3  47]
 [ 22 231   4  26   3   1  29]
 [  8   6 134   9   0   0  44]
 [ 37  14  11 205   5   0 129]
 [ 30   8   4  12  29  13  26]
 [  1   0   0   0   0  26  10]
 [ 53  81   4  82   6  11 388]]
=> Iteration 4:
Epoch 1:
[[264  14   2   7  26   4  75]
 [ 11 215   4  28   3   1  54]
 [  5   3 138   9   0   0  46]
 [ 23  14  13 209  12   1 129]
 [ 18  10   5  13  32  14  30]
 [  1   0   0   2   0  26   8]
 [ 27  31   8  77   8  14 460]]
Epoch 2:
[[311  14   1  10  12   3  41]
 [ 20 223   6  32   3   1  31]
 [ 10   2 139  17   0   0  33]
 [ 36   9  15 255   6   0  80]
 [ 30  11   3  14  30  13  21]
 [  1   1   0   2   0  26   7]
 [ 42  57  11 151  12   9 343]]
Epoch 3:
[[304  21   0   4   6   3  54]
 [ 16 230   3  27   2   1  37]
 [  8   7 134   5   0   0  47]
 [ 35  12  10 189   5   0 150]
 [ 33  11   1  14  19  15  29]
 [  1   0   0   2   0  26   8]
 [ 38  72   5  66   7   8 429]]
Epoch 4:
[[314  17   0   6   9   3  43]
 [ 23 231   3  25   2   1  31]
 [ 11   5 137   9   0   0  39]
 [ 35  12  13 218   5   0 118]
 [ 33  11   1  14  23  14  26]
 [  1   1   0   2   0  26   7]
 [ 51  90   9  85  12   9 369]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.243263   1.004563   0.645847   0.594848    0.603387
Iteration 1    1.271019   1.021746   0.610412   0.588498    0.570816
Iteration 2    1.245070   1.006627   0.630494   0.601519    0.603607
Iteration 3    1.279811   0.995910   0.644175   0.610069    0.614418
Iteration 4    1.263344   1.004786   0.617871   0.608944    0.603710

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.004652   1.030674   0.650631   0.586337    0.594520
Iteration 1    1.018183   1.052316   0.591377   0.595081    0.579626
Iteration 2    1.000727   1.043478   0.623362   0.602441    0.595789
Iteration 3    1.013583   1.019002   0.641157   0.603649    0.609972
Iteration 4    1.007762   1.009640   0.616016   0.617703    0.607193

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.911927   1.035032   0.625748   0.601230    0.595321
Iteration 1    0.921623   1.059723   0.606495   0.604158    0.588893
Iteration 2    0.900937   1.079796   0.600879   0.602585    0.589021
Iteration 3    0.906585   1.031614   0.611043   0.616939    0.603606
Iteration 4    0.911363   1.052212   0.626939   0.598027    0.592819

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.837155   1.062938   0.601933   0.605691    0.592755
Iteration 1    0.852969   1.055650   0.615882   0.613611    0.603167
Iteration 2    0.831008   1.071077   0.610429   0.608166    0.597434
Iteration 3    0.850687   1.048993   0.616650   0.606153    0.598860
Iteration 4    0.846440   1.061918   0.610369   0.605556    0.594773

