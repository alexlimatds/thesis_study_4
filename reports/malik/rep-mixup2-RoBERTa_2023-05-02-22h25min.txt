RESULTS REPORT (MIXUP 2 SINGLE SENTENCE CLASSIFICATION)
Model: RoBERTa
Encoder: roberta-base
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate : 1e-05
Number of epochs: 4
Mixup alpha: 0.1
Augmentation rate: 1.0
Classes to augment: ['Precedent', 'RulingByLowerCourt']
Average number of mixup vectors by epoch: 2820.0
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h45m03s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.427602  0.013984  1.171273 0.039787   0.6155  0.0461   0.5117  0.0344   0.5328   0.0278
  2    1.155277  0.006734  1.128922 0.030071   0.5979  0.0295   0.5557  0.0172   0.5639   0.0134
  3    1.043218  0.005820  1.131715 0.025625   0.5937  0.0161   0.5649  0.0073   0.5712   0.0079
  4    0.964275  0.008502  1.138179 0.019500   0.5833  0.0104   0.5859  0.0061   0.5784   0.0066

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[312   8   5  14   8   2  43]
 [ 47 174   7  41   2   0  45]
 [ 26   9 138   6   0   1  21]
 [ 60   9  27 201   5   1  98]
 [ 56   6   3  15  15   6  21]
 [ 10   0   0   4   2  15   6]
 [100  25  16  89   5  10 380]]
Epoch 2:
[[255   7   4  12  12   2 100]
 [ 22 191   5  35   0   0  63]
 [  8   3 134  10   0   0  46]
 [ 45   9  16 206   4   0 121]
 [ 36   7   3  16  13   2  45]
 [  4   0   1   4   0  16  12]
 [ 41  21  10  96   4   1 452]]
Epoch 3:
[[299   9   2   8  17   3  54]
 [ 30 197   5  27   4   1  52]
 [ 16   5 135   5   0   0  40]
 [ 50  11  17 197   7   0 119]
 [ 45  11   1   9  28   5  23]
 [  4   0   0   4   4  18   7]
 [ 85  35  11  77  11   7 399]]
Epoch 4:
[[285  12   1   8  22   3  61]
 [ 23 203   5  30   3   1  51]
 [ 14   8 132   6   2   2  37]
 [ 47  13  16 209   7   0 109]
 [ 36  13   1  12  30   9  21]
 [  1   0   0   4   1  26   5]
 [ 64  49  10  88  13  15 386]]
=> Iteration 1:
Epoch 1:
[[279   6   1  11  10   1  84]
 [ 27 185   2  30   1   0  71]
 [  4   4 115   3   0   0  75]
 [ 45   8  10 190   6   0 142]
 [ 40   5   1  13  20   1  42]
 [  6   0   1   3   2  11  14]
 [ 48  19   2  67   6   0 483]]
Epoch 2:
[[273   8   9   6  14   3  79]
 [ 31 187   7  21   1   0  69]
 [  4   4 142   4   0   0  47]
 [ 47  11  22 176   6   0 139]
 [ 30  11   5   7  32   5  32]
 [  3   0   0   2   1  20  11]
 [ 43  18  17  61   7   8 471]]
Epoch 3:
[[289  13   2   7  19   2  60]
 [ 29 195   3  28   1   0  60]
 [  9   8 128   7   0   0  49]
 [ 49  12  11 210   7   0 112]
 [ 32  14   2   9  31   6  28]
 [  2   0   0   4   3  18  10]
 [ 53  37   3  89  12   6 425]]
Epoch 4:
[[286  14   6   9  18   3  56]
 [ 30 197   6  32   5   0  46]
 [  7   8 143   7   0   1  35]
 [ 42  12  17 222   7   0 101]
 [ 24  16   4  11  33   9  25]
 [  1   0   0   4   1  25   6]
 [ 53  41  17 106  15  13 380]]
=> Iteration 2:
Epoch 1:
[[194  16   2   6   2   3 169]
 [  7 173   2  22   0   0 112]
 [  1   2 111   2   0   0  85]
 [ 30  14   7 145   1   0 204]
 [ 16   9   2  10   4   2  79]
 [  1   0   1   0   0  10  25]
 [ 27  21   2  34   0   1 540]]
Epoch 2:
[[235  21   2  30  26   6  72]
 [ 17 202   6  36   2   1  52]
 [ 11   4 138   3   0   0  45]
 [ 31  16  16 193   9   1 135]
 [ 20  10   4  26  22   9  31]
 [  2   0   0   0   1  20  14]
 [ 39  65   6  76  10   9 420]]
Epoch 3:
[[282  14   2   8  21   6  59]
 [ 27 201   3  25   2   1  57]
 [ 14   6 122   4   0   0  55]
 [ 41  16  14 187   6   0 137]
 [ 28  12   1  18  26  12  25]
 [  3   0   0   2   0  22  10]
 [ 65  53   2  63  13  12 417]]
Epoch 4:
[[267  18   5  13  26   5  58]
 [ 22 202   6  29   4   1  52]
 [  9   6 140   5   0   0  41]
 [ 41  15  13 213   7   0 112]
 [ 25  11   2  17  32  10  25]
 [  1   0   0   4   1  25   6]
 [ 56  58  10  88  13  12 388]]
=> Iteration 3:
Epoch 1:
[[259  30   1  14  11   7  70]
 [ 17 223   3  30   0   0  43]
 [  7   8 133   9   0   0  44]
 [ 37  21  20 203   7   1 112]
 [ 27  23   2  21  13  10  26]
 [  6   0   0   3   2  17   9]
 [ 53  59   8  93   2   6 404]]
Epoch 2:
[[245  17   2   4  39   5  80]
 [ 19 206   2  18   5   1  65]
 [  4   9 127   1   0   0  60]
 [ 36  16  12 159  14   1 163]
 [ 20  12   1   6  38  14  31]
 [  1   0   0   0   3  23  10]
 [ 49  28   8  46   9  11 474]]
Epoch 3:
[[294  12   1  11  22   5  47]
 [ 30 209   6  25   6   0  40]
 [ 11  10 139   7   0   0  34]
 [ 48  14  19 216   7   0  97]
 [ 45  10   1  13  27   7  19]
 [  2   0   0   4   3  23   5]
 [ 85  56  17 105  13  11 338]]
Epoch 4:
[[277  16   4  12  18   4  61]
 [ 25 206   6  25   2   0  52]
 [  8   8 141   8   0   0  36]
 [ 43  13  16 211   5   0 113]
 [ 35  14   1  11  25   9  27]
 [  0   0   1   2   2  23   9]
 [ 56  47  15  91   5  11 400]]
=> Iteration 4:
Epoch 1:
[[263   6   4   6  19   5  89]
 [ 25 192   3  29   5   1  61]
 [  4   3 122   4   0   1  67]
 [ 41  13  10 174  11   0 152]
 [ 32   5   2   7  29   8  39]
 [  5   0   0   0   1  17  14]
 [ 52  19   4  53   6   7 484]]
Epoch 2:
[[247   4  10  13  69   5  44]
 [ 27 182  12  41  19   0  35]
 [  8   3 154   7   3   0  26]
 [ 37  11  25 219  29   0  80]
 [ 24   5   7  15  52   3  16]
 [  2   0   0   4   7  18   6]
 [ 54  14  47 121  49   6 334]]
Epoch 3:
[[296   6   7   9  14   4  56]
 [ 28 207   9  28   2   0  42]
 [  8   6 140   8   0   0  39]
 [ 51  15  17 208   6   1 103]
 [ 41  10   2  13  21   7  28]
 [  4   0   0   0   0  21  12]
 [ 63  34  20  93   9   6 400]]
Epoch 4:
[[282  12   6   9  23   5  55]
 [ 22 219  10  27   4   1  33]
 [  9   6 141  13   0   1  31]
 [ 46  18  19 227  11   1  79]
 [ 34  14   1  14  26  11  22]
 [  2   0   0   2   1  22  10]
 [ 62  56  21 104  12  11 359]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.440191   1.194397   0.566297   0.524389    0.527670
Iteration 1    1.421855   1.130896   0.675389   0.511023    0.553323
Iteration 2    1.444646   1.232727   0.659489   0.446180    0.482858
Iteration 3    1.405398   1.171497   0.563985   0.535250    0.537148
Iteration 4    1.425920   1.126850   0.612465   0.541565    0.563001

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.164143   1.112109   0.633663   0.528216    0.558055
Iteration 1    1.152359   1.077309   0.627108   0.570001    0.585482
Iteration 2    1.152824   1.150895   0.560710   0.542780    0.546372
Iteration 3    1.145545   1.154697   0.598887   0.570964    0.571603
Iteration 4    1.161514   1.149598   0.569056   0.566496    0.557945

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.052438   1.135968   0.598703   0.557640    0.570453
Iteration 1    1.037257   1.097115   0.619113   0.562204    0.582826
Iteration 2    1.038667   1.168262   0.583012   0.557667    0.558956
Iteration 3    1.040169   1.147497   0.571186   0.575046    0.568080
Iteration 4    1.047557   1.109732   0.596476   0.572155    0.575555

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.971937   1.141185   0.585435   0.587652    0.578647
Iteration 1    0.962657   1.110518   0.590252   0.596034    0.588133
Iteration 2    0.958039   1.170443   0.583523   0.586689    0.579946
Iteration 3    0.952943   1.139718   0.593564   0.578964    0.577976
Iteration 4    0.975797   1.129032   0.563788   0.580302    0.567306

