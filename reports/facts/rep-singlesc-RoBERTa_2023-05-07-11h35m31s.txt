RESULTS REPORT (SINGLE SENTENCE CLASSIFICATION)
Model: RoBERTa
Encoder: roberta-base
Dataset: facts
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Freeze layers: False
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h49m59s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    0.519213  0.008956  0.344216 0.008296   0.7024  0.0494   0.6415  0.0393   0.6556   0.0165
  2    0.396121  0.002528  0.337667 0.004009   0.7353  0.0341   0.6489  0.0228   0.6806   0.0152
  3    0.338650  0.003981  0.342602 0.006862   0.7155  0.0139   0.6892  0.0137   0.7005   0.0070
  4    0.293542  0.001835  0.360279 0.005762   0.7084  0.0176   0.7025  0.0046   0.7043   0.0101

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
Other: 2 
=> Iteration 0:
Epoch 1:
[[ 183    4  205]
 [   0   17   20]
 [  47   18 1703]]
Epoch 2:
[[ 220    5  167]
 [   1   19   17]
 [  83   18 1667]]
Epoch 3:
[[ 256    3  133]
 [   2   18   17]
 [ 157   11 1600]]
Epoch 4:
[[ 249    4  139]
 [   1   20   16]
 [ 131   19 1618]]
=> Iteration 1:
Epoch 1:
[[ 223    7  162]
 [   2   21   14]
 [ 105   23 1640]]
Epoch 2:
[[ 200    2  190]
 [   1   13   23]
 [  73    4 1691]]
Epoch 3:
[[ 240    3  149]
 [   2   22   13]
 [ 108   18 1642]]
Epoch 4:
[[ 242    3  147]
 [   2   21   14]
 [  97   17 1654]]
=> Iteration 2:
Epoch 1:
[[ 202    8  182]
 [   3   19   15]
 [  77   28 1663]]
Epoch 2:
[[ 188    3  201]
 [   0   19   18]
 [  69   15 1684]]
Epoch 3:
[[ 257    3  132]
 [   3   19   15]
 [ 133   11 1624]]
Epoch 4:
[[ 245    3  144]
 [   2   20   15]
 [ 112   15 1641]]
=> Iteration 3:
Epoch 1:
[[ 244    6  142]
 [   2   16   19]
 [ 118    9 1641]]
Epoch 2:
[[ 213    4  175]
 [   0   18   19]
 [  78   11 1679]]
Epoch 3:
[[ 219    3  170]
 [   2   19   16]
 [  88   11 1669]]
Epoch 4:
[[ 245    3  144]
 [   2   21   14]
 [ 104   15 1649]]
=> Iteration 4:
Epoch 1:
[[ 191    1  200]
 [   1   10   26]
 [  71    2 1695]]
Epoch 2:
[[ 222    3  167]
 [   1   17   19]
 [  91    3 1674]]
Epoch 3:
[[ 236    3  153]
 [   1   19   17]
 [ 100   10 1658]]
Epoch 4:
[[ 235    3  154]
 [   1   21   15]
 [  92   13 1663]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.510043   0.337846   0.704949   0.629844    0.652443
Iteration 1    0.535326   0.357867   0.663535   0.688016    0.670060
Iteration 2    0.516170   0.349885   0.651951   0.656477    0.643070
Iteration 3    0.521760   0.336975   0.699038   0.661016    0.678473
Iteration 4    0.512765   0.338506   0.792606   0.572075    0.634051

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.393867   0.333297   0.692220   0.672537    0.678149
Iteration 1    0.401014   0.340237   0.767423   0.606001    0.661970
Iteration 2    0.394611   0.344241   0.709983   0.648531    0.670109
Iteration 3    0.395587   0.335139   0.724612   0.659838    0.686760
Iteration 4    0.395526   0.335422   0.782046   0.657540    0.706128

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.338826   0.337917   0.697884   0.681508    0.688598
Iteration 1    0.342253   0.338552   0.702514   0.711858    0.705424
Iteration 2    0.335956   0.350023   0.715566   0.695893    0.705136
Iteration 3    0.343512   0.351658   0.728075   0.672064    0.696338
Iteration 4    0.332706   0.334858   0.733683   0.684446    0.706774

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.293087   0.364751   0.677079   0.696968    0.686036
Iteration 1    0.295789   0.363955   0.711056   0.706812    0.707337
Iteration 2    0.292794   0.351524   0.706811   0.697903    0.701880
Iteration 3    0.295308   0.365857   0.716343   0.708420    0.711546
Iteration 4    0.290732   0.355308   0.730594   0.702556    0.714745

