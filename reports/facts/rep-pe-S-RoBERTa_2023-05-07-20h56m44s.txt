RESULTS REPORT (PE S)
Model: RoBERTa
Encoder: roberta-base
Dataset: facts
Evaluation: test set (5 random seeds)
Combination: S
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h51m06s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    0.593357  0.020246  0.378957 0.035576   0.6670  0.0445   0.6049  0.0372   0.6220   0.0200
  2    0.428919  0.015881  0.357418 0.016035   0.7274  0.0247   0.6387  0.0236   0.6734   0.0227
  3    0.356520  0.014966  0.366487 0.020710   0.7341  0.0422   0.6930  0.0279   0.7084   0.0172
  4    0.305958  0.010067  0.380283 0.022586   0.7142  0.0304   0.7022  0.0308   0.7050   0.0259

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
Other: 2 
=> Iteration 0:
Epoch 1:
[[ 217    5  170]
 [   3   11   23]
 [  77   16 1675]]
Epoch 2:
[[ 190    2  200]
 [   1   14   22]
 [  63   11 1694]]
Epoch 3:
[[ 270    2  120]
 [   2   20   15]
 [ 141   15 1612]]
Epoch 4:
[[ 245    3  144]
 [   0   22   15]
 [ 101   21 1646]]
=> Iteration 1:
Epoch 1:
[[ 159    5  228]
 [   4   15   18]
 [  95   21 1652]]
Epoch 2:
[[ 196    2  194]
 [   2   15   20]
 [  89   13 1666]]
Epoch 3:
[[ 224    3  165]
 [   2   20   15]
 [ 109   19 1640]]
Epoch 4:
[[ 213    3  176]
 [   2   17   18]
 [  93   20 1655]]
=> Iteration 2:
Epoch 1:
[[ 175    6  211]
 [   2   16   19]
 [  59   14 1695]]
Epoch 2:
[[ 187    4  201]
 [   2   21   14]
 [  61   10 1697]]
Epoch 3:
[[ 207    2  183]
 [   2   19   16]
 [  75    3 1690]]
Epoch 4:
[[ 235    3  154]
 [   2   22   13]
 [  94   13 1661]]
=> Iteration 3:
Epoch 1:
[[ 275    7  110]
 [   5   16   16]
 [ 198   18 1552]]
Epoch 2:
[[ 205    2  185]
 [   0   17   20]
 [  76   12 1680]]
Epoch 3:
[[ 237    2  153]
 [   2   25   10]
 [ 105   16 1647]]
Epoch 4:
[[ 239    3  150]
 [   1   25   11]
 [ 105   20 1643]]
=> Iteration 4:
Epoch 1:
[[ 204    2  186]
 [   5    8   24]
 [  96    2 1670]]
Epoch 2:
[[ 208    3  181]
 [   1   18   18]
 [  69    7 1692]]
Epoch 3:
[[ 225    4  163]
 [   2   18   17]
 [  91    6 1671]]
Epoch 4:
[[ 228    3  161]
 [   2   21   14]
 [  87    8 1673]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.588366   0.329026   0.657024   0.599422    0.623360
Iteration 1    0.574293   0.431173   0.617508   0.581802    0.591700
Iteration 2    0.592535   0.361897   0.688830   0.612524    0.637878
Iteration 3    0.631786   0.405167   0.630156   0.670597    0.647732
Iteration 4    0.579807   0.367520   0.741272   0.560398    0.609156

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.421615   0.340623   0.716895   0.607072    0.648463
Iteration 1    0.415286   0.387488   0.689699   0.615904    0.646153
Iteration 2    0.427241   0.348296   0.745184   0.668150    0.696057
Iteration 3    0.459763   0.357278   0.723057   0.644215    0.676335
Iteration 4    0.420688   0.353403   0.761941   0.658037    0.699862

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.353986   0.330766   0.705673   0.713694    0.709520
Iteration 1    0.347061   0.392694   0.681982   0.679857    0.678906
Iteration 2    0.353631   0.362424   0.805064   0.665819    0.719877
Iteration 3    0.385232   0.379321   0.726765   0.737276    0.729883
Iteration 4    0.342689   0.367228   0.751053   0.668534    0.703703

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.304693   0.355627   0.699422   0.716863    0.705144
Iteration 1    0.300053   0.417900   0.670546   0.646304    0.655084
Iteration 2    0.303835   0.362125   0.732520   0.711188    0.720180
Iteration 3    0.325140   0.392487   0.708114   0.738223    0.718914
Iteration 4    0.296068   0.373275   0.760265   0.698489    0.725729

