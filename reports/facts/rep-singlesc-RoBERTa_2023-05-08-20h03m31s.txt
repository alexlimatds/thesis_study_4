RESULTS REPORT (SINGLE SENTENCE CLASSIFICATION)
Model: RoBERTa
Encoder: roberta-base
Dataset: facts
Evaluation: development set (3 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Freeze layers: False
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 01h40m57s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    0.520513  0.010769  0.550625 0.010509   0.5885  0.0294   0.5419  0.0028   0.5567   0.0082
  2    0.396497  0.003208  0.569082 0.025894   0.6078  0.0302   0.5251  0.0212   0.5518   0.0150
  3    0.339012  0.002574  0.604507 0.021424   0.6078  0.0109   0.5649  0.0102   0.5824   0.0106
  4    0.293890  0.001348  0.648095 0.014421   0.6001  0.0047   0.5607  0.0101   0.5775   0.0076

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
Other: 2 
=> Iteration 0:
Epoch 1:
[[ 155    8  296]
 [   0   17   32]
 [  95   13 1526]]
Epoch 2:
[[ 203   11  245]
 [   0   16   33]
 [ 162   13 1459]]
Epoch 3:
[[ 255    6  198]
 [   1   15   33]
 [ 227   12 1395]]
Epoch 4:
[[ 237   10  212]
 [   1   17   31]
 [ 214   12 1408]]
=> Iteration 1:
Epoch 1:
[[ 180    7  272]
 [   1   18   30]
 [ 176   23 1435]]
Epoch 2:
[[ 168    3  288]
 [   1   11   37]
 [ 124    6 1504]]
Epoch 3:
[[ 223    9  227]
 [   1   17   31]
 [ 177   12 1445]]
Epoch 4:
[[ 217    9  233]
 [   2   15   32]
 [ 179   12 1443]]
=> Iteration 2:
Epoch 1:
[[ 172   14  273]
 [   0   17   32]
 [ 143   21 1470]]
Epoch 2:
[[ 156   10  293]
 [   0   15   34]
 [ 136   15 1483]]
Epoch 3:
[[ 231    9  219]
 [   1   14   34]
 [ 214   11 1409]]
Epoch 4:
[[ 223   10  226]
 [   1   15   33]
 [ 206   11 1417]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.510043   0.536481   0.630151   0.539511    0.567680
Iteration 1    0.535326   0.561648   0.568446   0.545906    0.554563
Iteration 2    0.516170   0.553745   0.567041   0.540433    0.547834

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.393867   0.537147   0.598706   0.553899    0.572629
Iteration 1    0.401014   0.569530   0.648562   0.503648    0.544753
Iteration 2    0.394611   0.600570   0.576195   0.517860    0.537911

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.338826   0.576849   0.613476   0.571804    0.587694
Iteration 1    0.342253   0.607622   0.617327   0.572370    0.591819
Iteration 2    0.335956   0.629049   0.592492   0.550428    0.567607

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.293087   0.634444   0.604350   0.574989    0.587967
Iteration 1    0.295789   0.668043   0.602247   0.553999    0.574305
Iteration 2    0.292794   0.641799   0.593579   0.553053    0.570274

