RESULTS REPORT (PE C)
Model: InCaseLaw
Encoder: law-ai/InCaseLawBERT
Dataset: facts
Evaluation: test set (5 random seeds)
Combination: C
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h52m06s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    0.484850  0.014281  0.317661 0.012387   0.7109  0.0136   0.7299  0.0421   0.7155   0.0176
  2    0.329126  0.006442  0.316931 0.007716   0.7175  0.0138   0.7451  0.0262   0.7267   0.0123
  3    0.266277  0.004870  0.344468 0.011501   0.7111  0.0100   0.7575  0.0034   0.7286   0.0074
  4    0.225883  0.003313  0.359434 0.012025   0.7131  0.0094   0.7501  0.0114   0.7264   0.0083

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
Other: 2 
=> Iteration 0:
Epoch 1:
[[ 304    3   85]
 [   2   26    9]
 [ 165   27 1576]]
Epoch 2:
[[ 260    3  129]
 [   1   26   10]
 [  90   26 1652]]
Epoch 3:
[[ 255    3  134]
 [   1   25   11]
 [  94   27 1647]]
Epoch 4:
[[ 261    3  128]
 [   1   25   11]
 [ 102   26 1640]]
=> Iteration 1:
Epoch 1:
[[ 206    3  183]
 [   1   19   17]
 [  57   18 1693]]
Epoch 2:
[[ 267    2  123]
 [   1   18   18]
 [ 116   15 1637]]
Epoch 3:
[[ 261    3  128]
 [   1   25   11]
 [  99   27 1642]]
Epoch 4:
[[ 248    2  142]
 [   1   23   13]
 [  92   23 1653]]
=> Iteration 2:
Epoch 1:
[[ 265    1  126]
 [   1   22   14]
 [ 117   18 1633]]
Epoch 2:
[[ 267    1  124]
 [   1   24   12]
 [ 107   18 1643]]
Epoch 3:
[[ 266    3  123]
 [   1   25   11]
 [ 106   22 1640]]
Epoch 4:
[[ 269    2  121]
 [   1   25   11]
 [ 111   22 1635]]
=> Iteration 3:
Epoch 1:
[[ 270    2  120]
 [   1   24   12]
 [ 106   22 1640]]
Epoch 2:
[[ 240    2  150]
 [   0   24   13]
 [  62   22 1684]]
Epoch 3:
[[ 255    2  135]
 [   1   25   11]
 [  84   22 1662]]
Epoch 4:
[[ 255    2  135]
 [   0   25   12]
 [  82   22 1664]]
=> Iteration 4:
Epoch 1:
[[ 242    2  148]
 [   1   21   15]
 [  93   16 1659]]
Epoch 2:
[[ 282    2  108]
 [   1   25   11]
 [ 124   26 1618]]
Epoch 3:
[[ 269    2  121]
 [   1   25   11]
 [ 113   21 1634]]
Epoch 4:
[[ 246    2  144]
 [   0   25   12]
 [  90   23 1655]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.474680   0.329072   0.684478   0.789872    0.726824
Iteration 1    0.491433   0.325677   0.716550   0.665534    0.682146
Iteration 2    0.509760   0.325142   0.716510   0.731419    0.723437
Iteration 3    0.470642   0.295409   0.713896   0.755009    0.731157
Iteration 4    0.477735   0.313008   0.723079   0.707754    0.713900

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.329904   0.304007   0.711953   0.766786    0.731144
Iteration 1    0.331200   0.320840   0.710099   0.697838    0.703813
Iteration 2    0.339194   0.312342   0.731231   0.753023    0.740879
Iteration 3    0.319686   0.322795   0.735484   0.737794    0.729341
Iteration 4    0.325648   0.324671   0.698688   0.770074    0.728230

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.265382   0.330129   0.700734   0.752582    0.718697
Iteration 1    0.269625   0.360380   0.699830   0.756742    0.720679
Iteration 2    0.273775   0.346112   0.712534   0.760616    0.732056
Iteration 3    0.260642   0.332992   0.726484   0.755410    0.735882
Iteration 4    0.261962   0.352725   0.716146   0.762036    0.735720

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.225747   0.341796   0.700621   0.756365    0.721551
Iteration 1    0.225631   0.373694   0.706903   0.729743    0.714115
Iteration 2    0.231825   0.353542   0.713846   0.762225    0.734140
Iteration 3    0.221677   0.355980   0.728570   0.755787    0.736951
Iteration 4    0.224538   0.372158   0.715334   0.746438    0.725125

